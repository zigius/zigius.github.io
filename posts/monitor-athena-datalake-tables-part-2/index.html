<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>Monitor Athena Datalake Tables Part 2 | zlog - the zigius blog</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="In the previous post we explored various monitoring solutions for monitoring athena tables. One of the scenarios we wanted to be able to monitor, was a case where a partition has been unintentinally deleted from an athena table
We decided we will use S3 inventory to monitor this flow.
This is how we do it:
First let&rsquo;s try and break down the pseudo code we need to write:
1. get all athena tables partitions, using glue 2."><meta name=generator content="Hugo 0.109.0"><meta name=robots content="noindex, nofollow"><link rel=stylesheet href=/ananke/css/main.min.css><meta property="og:title" content="Monitor Athena Datalake Tables Part 2"><meta property="og:description" content="In the previous post we explored various monitoring solutions for monitoring athena tables. One of the scenarios we wanted to be able to monitor, was a case where a partition has been unintentinally deleted from an athena table
We decided we will use S3 inventory to monitor this flow.
This is how we do it:
First let&rsquo;s try and break down the pseudo code we need to write:
1. get all athena tables partitions, using glue 2."><meta property="og:type" content="article"><meta property="og:url" content="https://zigius.github.io/posts/monitor-athena-datalake-tables-part-2/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-01-01T16:12:24+02:00"><meta property="article:modified_time" content="2023-01-01T16:12:24+02:00"><meta itemprop=name content="Monitor Athena Datalake Tables Part 2"><meta itemprop=description content="In the previous post we explored various monitoring solutions for monitoring athena tables. One of the scenarios we wanted to be able to monitor, was a case where a partition has been unintentinally deleted from an athena table
We decided we will use S3 inventory to monitor this flow.
This is how we do it:
First let&rsquo;s try and break down the pseudo code we need to write:
1. get all athena tables partitions, using glue 2."><meta itemprop=datePublished content="2023-01-01T16:12:24+02:00"><meta itemprop=dateModified content="2023-01-01T16:12:24+02:00"><meta itemprop=wordCount content="1199"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="Monitor Athena Datalake Tables Part 2"><meta name=twitter:description content="In the previous post we explored various monitoring solutions for monitoring athena tables. One of the scenarios we wanted to be able to monitor, was a case where a partition has been unintentinally deleted from an athena table
We decided we will use S3 inventory to monitor this flow.
This is how we do it:
First let&rsquo;s try and break down the pseudo code we need to write:
1. get all athena tables partitions, using glue 2."></head><body class="ma0 avenir bg-near-white"><header><div class=bg-black><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/ class="f3 fw2 hover-white no-underline white-90 dib">zlog - the zigius blog</a><div class="flex-l items-center"><div class=ananke-socials></div></div></div></nav></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked">POSTS</aside><div id=sharing class="mt3 ananke-socials"></div><h1 class="f1 athelas mt3 mb1">Monitor Athena Datalake Tables Part 2</h1><time class="f6 mv4 dib tracked" datetime=2023-01-01T16:12:24+02:00>January 1, 2023</time></header><div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>In the <a href=https://zigius.github.io/posts/monitor-athena-datalake-tables/>previous post</a> we explored various monitoring solutions
for monitoring athena tables.
One of the scenarios we wanted to be able to monitor, was a case where a partition has been unintentinally deleted from an athena table</p><p>We decided we will use S3 inventory to monitor this flow.</p><p>This is how we do it:</p><p>First let&rsquo;s try and break down the pseudo code we need to write:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>1. get all athena tables partitions, using glue
</span></span><span style=display:flex><span>2. get all paths in our s3 datalake bucket
</span></span><span style=display:flex><span>3. group paths list by the location of the date partition. *ORDER MATTERS* (example: purchase_events table has three partitions - purchase_date, supplier, provider. will be placed in group 0).
</span></span><span style=display:flex><span>This is required in order to query the data efficiently.
</span></span><span style=display:flex><span>4. for each group, get size of each partition in group
</span></span><span style=display:flex><span>5. Filter partitions with invalid dates
</span></span><span style=display:flex><span>6. send metric for each date partition with it&#39;s size, date, and table properties.
</span></span></code></pre></div><p>First, let&rsquo;s look at the code snippet of the module and go over the code implementation. Don&rsquo;t worry, we will soon break it down to smaller pieces.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>monitor_athena_partitions_deletions</span>(self):
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    athena_tables <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_get_all_tables()
</span></span><span style=display:flex><span>    all_bucket_paths <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_get_all_bucket_paths()
</span></span><span style=display:flex><span>    tagged_paths <span style=color:#f92672>=</span> [self<span style=color:#f92672>.</span>_get_tags(bucket_path_id<span style=color:#f92672>=</span>o) <span style=color:#66d9ef>for</span> o <span style=color:#f92672>in</span> all_bucket_paths<span style=color:#f92672>.</span>bucket_path<span style=color:#f92672>.</span>values]
</span></span><span style=display:flex><span>    paths_grouped_by_date_partition <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_get_paths_grouped_by_date_partition(tagged_paths, athena_tables)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    dfs <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> k, v <span style=color:#f92672>in</span> paths_grouped_by_date_partition<span style=color:#f92672>.</span>items():
</span></span><span style=display:flex><span>        bucket_paths_ids <span style=color:#f92672>=</span> [<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;&#39;</span><span style=color:#e6db74>{</span>o[<span style=color:#e6db74>&#39;bucket_path_id&#39;</span>]<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;&#34;</span> <span style=color:#66d9ef>for</span> o <span style=color:#f92672>in</span> v]
</span></span><span style=display:flex><span>        query <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        select
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            split_part(key, &#39;/&#39;, 5) as bucket_path,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            split_part(key, &#39;/&#39;, </span><span style=color:#e6db74>{</span><span style=color:#ae81ff>8</span> <span style=color:#f92672>+</span> k<span style=color:#e6db74>}</span><span style=color:#e6db74>) as partition_field,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            sum(size) as sum_size
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        from &#34;</span><span style=color:#e6db74>{</span>AsIs(self<span style=color:#f92672>.</span>_config[<span style=color:#e6db74>&#34;s3_inventory_table_schema&#34;</span>])<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;.&#34;</span><span style=color:#e6db74>{</span>AsIs(self<span style=color:#f92672>.</span>_config[<span style=color:#e6db74>&#34;table_name&#34;</span>])<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        where dt = &#39;</span><span style=color:#e6db74>{</span>self<span style=color:#f92672>.</span>_get_dt()<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            and is_latest
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            and not is_delete_marker
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            and split_part(key, &#39;/&#39;, 4) = &#39;athena&#39;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            and split_part(key, &#39;/&#39;, 2) = &#39;production&#39;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            and split_part(key, &#39;/&#39;, 7) = &#39;output&#39; -- only check output folder
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            and split_part(key, &#39;/&#39;, 5) in (</span><span style=color:#e6db74>{</span><span style=color:#e6db74>&#34;,&#34;</span><span style=color:#f92672>.</span>join(bucket_paths_ids)<span style=color:#e6db74>}</span><span style=color:#e6db74>)
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        group by 1, 2
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>_logger<span style=color:#f92672>.</span>info(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;query: </span><span style=color:#e6db74>{</span>query<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>        res <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_sql(query, self<span style=color:#f92672>.</span>connection)
</span></span><span style=display:flex><span>        dfs<span style=color:#f92672>.</span>append(res)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>concat(dfs)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># filter outputs where the date partition column in not really a date.</span>
</span></span><span style=display:flex><span>    df[<span style=color:#e6db74>&#34;mask&#34;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#34;partition_field&#34;</span>]<span style=color:#f92672>.</span>str<span style=color:#f92672>.</span>contains(<span style=color:#e6db74>r</span><span style=color:#e6db74>&#34;.*=\d</span><span style=color:#e6db74>{4}</span><span style=color:#e6db74>-\d</span><span style=color:#e6db74>{2}</span><span style=color:#e6db74>-\d</span><span style=color:#e6db74>{2}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>    df <span style=color:#f92672>=</span> df[df[<span style=color:#e6db74>&#34;mask&#34;</span>] <span style=color:#f92672>==</span> <span style=color:#66d9ef>True</span>]
</span></span><span style=display:flex><span>    df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>drop(columns<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;mask&#34;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># filter column where the date partition is invalid. example: 2339-06-03</span>
</span></span><span style=display:flex><span>    df[<span style=color:#e6db74>&#34;partition_fields_clean&#34;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#34;partition_field&#34;</span>]<span style=color:#f92672>.</span>apply(<span style=color:#66d9ef>lambda</span> x: x<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#34;=&#34;</span>)[<span style=color:#ae81ff>1</span>])
</span></span><span style=display:flex><span>    df[<span style=color:#e6db74>&#34;is_valid_date&#34;</span>] <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>to_datetime(df[<span style=color:#e6db74>&#34;partition_fields_clean&#34;</span>], format<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;%Y-%m-</span><span style=color:#e6db74>%d</span><span style=color:#e6db74>&#34;</span>, errors<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;coerce&#34;</span>)<span style=color:#f92672>.</span>notna()
</span></span><span style=display:flex><span>    df <span style=color:#f92672>=</span> df[df[<span style=color:#e6db74>&#34;is_valid_date&#34;</span>] <span style=color:#f92672>==</span> <span style=color:#66d9ef>True</span>]
</span></span><span style=display:flex><span>    df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>drop(columns<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;partition_fields_clean&#34;</span>, <span style=color:#e6db74>&#34;is_valid_date&#34;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># filter column where the date partition is in the future</span>
</span></span><span style=display:flex><span>    df[<span style=color:#e6db74>&#34;is_future&#34;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#34;partition_field&#34;</span>]<span style=color:#f92672>.</span>apply(<span style=color:#66d9ef>lambda</span> x: datetime<span style=color:#f92672>.</span>datetime<span style=color:#f92672>.</span>strptime(x<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#34;=&#34;</span>)[<span style=color:#ae81ff>1</span>], <span style=color:#e6db74>&#34;%Y-%m-</span><span style=color:#e6db74>%d</span><span style=color:#e6db74>&#34;</span>) <span style=color:#f92672>&gt;</span> datetime<span style=color:#f92672>.</span>datetime<span style=color:#f92672>.</span>now())
</span></span><span style=display:flex><span>    df <span style=color:#f92672>=</span> df[df[<span style=color:#e6db74>&#34;is_future&#34;</span>] <span style=color:#f92672>==</span> <span style=color:#66d9ef>False</span>]
</span></span><span style=display:flex><span>    df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>drop(columns<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;is_future&#34;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> _, row <span style=color:#f92672>in</span> df<span style=color:#f92672>.</span>iterrows():
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        tags <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_get_tags(bucket_path_id<span style=color:#f92672>=</span>row[<span style=color:#e6db74>&#34;bucket_path&#34;</span>])
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>_metrics<span style=color:#f92672>.</span>value(
</span></span><span style=display:flex><span>            measurement_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;athena_delete_monitoring_partition_sizes&#34;</span>,
</span></span><span style=display:flex><span>            value<span style=color:#f92672>=</span>row[<span style=color:#e6db74>&#34;sum_size&#34;</span>],
</span></span><span style=display:flex><span>            tags<span style=color:#f92672>=</span>{<span style=color:#f92672>**</span>tags, <span style=color:#f92672>**</span>{<span style=color:#e6db74>&#34;partition_date&#34;</span>: row[<span style=color:#e6db74>&#34;partition_field&#34;</span>]<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#34;=&#34;</span>)[<span style=color:#ae81ff>1</span>]}},
</span></span><span style=display:flex><span>        )
</span></span></code></pre></div><p>The first line in the code snippet uses glue to get all the athena tables</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>monitor_athena_partitions_deletions</span>(self):
</span></span><span style=display:flex><span>    athena_tables <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_get_all_tables()
</span></span><span style=display:flex><span>    <span style=color:#75715e># ...</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_get_all_tables</span>(self, database_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;datalake&#34;</span>):
</span></span><span style=display:flex><span>    <span style=color:#f92672>import</span> boto3
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    client <span style=color:#f92672>=</span> boto3<span style=color:#f92672>.</span>client(<span style=color:#e6db74>&#34;glue&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Create an empty list to store the tables</span>
</span></span><span style=display:flex><span>    response <span style=color:#f92672>=</span> client<span style=color:#f92672>.</span>get_tables(DatabaseName<span style=color:#f92672>=</span>database_name)
</span></span><span style=display:flex><span>    tables <span style=color:#f92672>=</span> response[<span style=color:#e6db74>&#34;TableList&#34;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Use a loop to retrieve all the tables from the database</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>while</span> response<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;NextToken&#34;</span>, <span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>        <span style=color:#75715e># Call the get_tables method of the AWS Glue client, passing the NextToken parameter if it&#39;s not empty</span>
</span></span><span style=display:flex><span>        response <span style=color:#f92672>=</span> client<span style=color:#f92672>.</span>get_tables(DatabaseName<span style=color:#f92672>=</span>database_name, NextToken<span style=color:#f92672>=</span>response[<span style=color:#e6db74>&#34;NextToken&#34;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Append the tables from the response to the list of tables</span>
</span></span><span style=display:flex><span>        tables<span style=color:#f92672>.</span>extend(response[<span style=color:#e6db74>&#34;TableList&#34;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> tables
</span></span></code></pre></div><p>We use the glue boto client to retrieve all the metadata for all of our athena tables.
We need the metadata of the tables to determine which table has which partitions.</p><p>Now, we continue to get all the S3 bucket paths</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>monitor_athena_partitions_deletions</span>(self):
</span></span><span style=display:flex><span>    <span style=color:#75715e># ...</span>
</span></span><span style=display:flex><span>    all_bucket_paths <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_get_all_bucket_paths()
</span></span><span style=display:flex><span>    <span style=color:#75715e># ...</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_get_all_bucket_paths</span>(self):
</span></span><span style=display:flex><span>    query <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    select
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        split_part(key, &#39;/&#39;, 5) as bucket_path
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    from &#34;</span><span style=color:#e6db74>{</span>AsIs(self<span style=color:#f92672>.</span>_config[<span style=color:#e6db74>&#34;s3_inventory_table_schema&#34;</span>])<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;.&#34;</span><span style=color:#e6db74>{</span>AsIs(self<span style=color:#f92672>.</span>_config[<span style=color:#e6db74>&#34;table_name&#34;</span>])<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    where dt = &#39;</span><span style=color:#e6db74>{</span>self<span style=color:#f92672>.</span>_get_dt()<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        and split_part(key, &#39;/&#39;, 4) = &#39;athena&#39;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        and split_part(key, &#39;/&#39;, 2) = &#39;production&#39;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        and split_part(key, &#39;/&#39;, 7) = &#39;output&#39; -- only check output folder
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    group by 1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    self<span style=color:#f92672>.</span>_logger<span style=color:#f92672>.</span>info(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;query: </span><span style=color:#e6db74>{</span>query<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>    res <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_sql(query, self<span style=color:#f92672>.</span>connection)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> res
</span></span></code></pre></div><p>We use our s3 inventory table to get all the paths that for all of our athena tables. An example key looks something like this:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fs data-lang=fs><span style=display:flex><span><span style=color:#a6e22e>&lt;bucket-name&gt;/datalake/production/outputs/athena/&lt;output-id&gt;/&lt;output-version&gt;/output/&lt;partition_field1&gt;=&lt;partition_field1value&gt;/&lt;partition_date&gt;=&lt;partition_date_value&gt;/compaction_id=6/2022_12_22_11_51_output.parquet.p00017</span>
</span></span></code></pre></div><p>We want to find all the output ids (located at the fifth slash in the key).
Check out the previous article for more info.</p><p>Let&rsquo;s continue and get all the paths grouped by date.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>monitor_athena_partitions_deletions</span>(self):
</span></span><span style=display:flex><span>    <span style=color:#75715e># ...</span>
</span></span><span style=display:flex><span>    tagged_paths <span style=color:#f92672>=</span> [self<span style=color:#f92672>.</span>_get_tags(bucket_path_id<span style=color:#f92672>=</span>o) <span style=color:#66d9ef>for</span> o <span style=color:#f92672>in</span> all_bucket_paths<span style=color:#f92672>.</span>bucket_path<span style=color:#f92672>.</span>values]
</span></span><span style=display:flex><span>    paths_grouped_by_date_partition <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_get_paths_grouped_by_date_partition(tagged_paths, athena_tables)
</span></span><span style=display:flex><span>    <span style=color:#75715e># ...</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_get_tags</span>(self, bucket_path_id):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;table_name&#34;</span>: self<span style=color:#f92672>.</span>_get_table_name(bucket_path_id),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;bucket_path_id&#34;</span>: bucket_path_id,
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> tags
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_get_paths_grouped_by_date_partition</span>(self, tagged_paths, athena_tables):
</span></span><span style=display:flex><span>    grouped_paths <span style=color:#f92672>=</span> {}
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> tagged_path <span style=color:#f92672>in</span> tagged_paths:
</span></span><span style=display:flex><span>        athena_table <span style=color:#f92672>=</span> [o <span style=color:#66d9ef>for</span> o <span style=color:#f92672>in</span> athena_tables <span style=color:#66d9ef>if</span> o<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;Name&#34;</span>, <span style=color:#66d9ef>None</span>) <span style=color:#f92672>==</span> tagged_path<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;table_name&#34;</span>, <span style=color:#e6db74>&#34;&#34;</span>)]
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> athena_table:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>continue</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> i, v <span style=color:#f92672>in</span> enumerate(athena_table[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;PartitionKeys&#34;</span>, [])):
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> v[<span style=color:#e6db74>&#34;Type&#34;</span>] <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;date&#34;</span>:
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>if</span> i <span style=color:#f92672>not</span> <span style=color:#f92672>in</span> grouped_paths:
</span></span><span style=display:flex><span>                    grouped_paths[i] <span style=color:#f92672>=</span> [tagged_path]
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>                    grouped_paths[i]<span style=color:#f92672>.</span>append(tagged_path)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> grouped_paths
</span></span></code></pre></div><p>This code snippet groups the athena tables by the location of their date partition. We assume all athena tables have 1 date partition key, but can have multiple other partitions.
We are writing a query that aggregates data by the date partition, so to reduce calls to S3 inventory we group all the tables where the date partition is in the same location in the path together.</p><p>Now to run the actual queries</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>monitor_athena_partitions_deletions</span>(self):
</span></span><span style=display:flex><span>    <span style=color:#75715e># ...</span>
</span></span><span style=display:flex><span>    dfs <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> k, v <span style=color:#f92672>in</span> paths_grouped_by_date_partition<span style=color:#f92672>.</span>items():
</span></span><span style=display:flex><span>        bucket_paths_ids <span style=color:#f92672>=</span> [<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;&#39;</span><span style=color:#e6db74>{</span>o[<span style=color:#e6db74>&#39;bucket_path_id&#39;</span>]<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;&#34;</span> <span style=color:#66d9ef>for</span> o <span style=color:#f92672>in</span> v]
</span></span><span style=display:flex><span>        query <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        select
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            split_part(key, &#39;/&#39;, 5) as bucket_path,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            split_part(key, &#39;/&#39;, </span><span style=color:#e6db74>{</span><span style=color:#ae81ff>8</span> <span style=color:#f92672>+</span> k<span style=color:#e6db74>}</span><span style=color:#e6db74>) as partition_field,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            sum(size) as sum_size
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        from &#34;</span><span style=color:#e6db74>{</span>AsIs(self<span style=color:#f92672>.</span>_config[<span style=color:#e6db74>&#34;s3_inventory_table_schema&#34;</span>])<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;.&#34;</span><span style=color:#e6db74>{</span>AsIs(self<span style=color:#f92672>.</span>_config[<span style=color:#e6db74>&#34;table_name&#34;</span>])<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        where dt = &#39;</span><span style=color:#e6db74>{</span>self<span style=color:#f92672>.</span>_get_dt()<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            and is_latest
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            and not is_delete_marker
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            and split_part(key, &#39;/&#39;, 4) = &#39;athena&#39;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            and split_part(key, &#39;/&#39;, 2) = &#39;production&#39;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            and split_part(key, &#39;/&#39;, 7) = &#39;output&#39; -- only check output folder
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            and split_part(key, &#39;/&#39;, 5) in (</span><span style=color:#e6db74>{</span><span style=color:#e6db74>&#34;,&#34;</span><span style=color:#f92672>.</span>join(bucket_paths_ids)<span style=color:#e6db74>}</span><span style=color:#e6db74>)
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        group by 1, 2
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>_logger<span style=color:#f92672>.</span>info(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;query: </span><span style=color:#e6db74>{</span>query<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>        res <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_sql(query, self<span style=color:#f92672>.</span>connection)
</span></span><span style=display:flex><span>        dfs<span style=color:#f92672>.</span>append(res)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>concat(dfs)
</span></span><span style=display:flex><span>    <span style=color:#75715e># ...</span>
</span></span></code></pre></div><p>This code runs the actual queries against the S3 inventory table, and aggregates the results in a single datafram, <code>df</code>.</p><p>Now we clean our dataframe and remove invalid rows</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>monitor_athena_partitions_deletions</span>(self):
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># ...</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># filter outputs where the date partition column in not really a date.</span>
</span></span><span style=display:flex><span>    df[<span style=color:#e6db74>&#34;mask&#34;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#34;partition_field&#34;</span>]<span style=color:#f92672>.</span>str<span style=color:#f92672>.</span>contains(<span style=color:#e6db74>r</span><span style=color:#e6db74>&#34;.*=\d</span><span style=color:#e6db74>{4}</span><span style=color:#e6db74>-\d</span><span style=color:#e6db74>{2}</span><span style=color:#e6db74>-\d</span><span style=color:#e6db74>{2}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>    df <span style=color:#f92672>=</span> df[df[<span style=color:#e6db74>&#34;mask&#34;</span>] <span style=color:#f92672>==</span> <span style=color:#66d9ef>True</span>]
</span></span><span style=display:flex><span>    df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>drop(columns<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;mask&#34;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># filter column where the date partition is invalid. example: 2339-06-03</span>
</span></span><span style=display:flex><span>    df[<span style=color:#e6db74>&#34;partition_fields_clean&#34;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#34;partition_field&#34;</span>]<span style=color:#f92672>.</span>apply(<span style=color:#66d9ef>lambda</span> x: x<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#34;=&#34;</span>)[<span style=color:#ae81ff>1</span>])
</span></span><span style=display:flex><span>    df[<span style=color:#e6db74>&#34;is_valid_date&#34;</span>] <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>to_datetime(df[<span style=color:#e6db74>&#34;partition_fields_clean&#34;</span>], format<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;%Y-%m-</span><span style=color:#e6db74>%d</span><span style=color:#e6db74>&#34;</span>, errors<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;coerce&#34;</span>)<span style=color:#f92672>.</span>notna()
</span></span><span style=display:flex><span>    df <span style=color:#f92672>=</span> df[df[<span style=color:#e6db74>&#34;is_valid_date&#34;</span>] <span style=color:#f92672>==</span> <span style=color:#66d9ef>True</span>]
</span></span><span style=display:flex><span>    df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>drop(columns<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;partition_fields_clean&#34;</span>, <span style=color:#e6db74>&#34;is_valid_date&#34;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># filter column where the date partition is in the future</span>
</span></span><span style=display:flex><span>    df[<span style=color:#e6db74>&#34;is_future&#34;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#34;partition_field&#34;</span>]<span style=color:#f92672>.</span>apply(<span style=color:#66d9ef>lambda</span> x: datetime<span style=color:#f92672>.</span>datetime<span style=color:#f92672>.</span>strptime(x<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#34;=&#34;</span>)[<span style=color:#ae81ff>1</span>], <span style=color:#e6db74>&#34;%Y-%m-</span><span style=color:#e6db74>%d</span><span style=color:#e6db74>&#34;</span>) <span style=color:#f92672>&gt;</span> datetime<span style=color:#f92672>.</span>datetime<span style=color:#f92672>.</span>now())
</span></span><span style=display:flex><span>    df <span style=color:#f92672>=</span> df[df[<span style=color:#e6db74>&#34;is_future&#34;</span>] <span style=color:#f92672>==</span> <span style=color:#66d9ef>False</span>]
</span></span><span style=display:flex><span>    df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>drop(columns<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;is_future&#34;</span>])
</span></span><span style=display:flex><span>    <span style=color:#75715e># ...</span>
</span></span></code></pre></div><p>And lastly, we send a metric for every partition size we have gathered</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>monitor_athena_partitions_deletions</span>(self):
</span></span><span style=display:flex><span>    <span style=color:#75715e># ...</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> _, row <span style=color:#f92672>in</span> df<span style=color:#f92672>.</span>iterrows():
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        tags <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_get_tags(bucket_path_id<span style=color:#f92672>=</span>row[<span style=color:#e6db74>&#34;bucket_path&#34;</span>])
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>_metrics<span style=color:#f92672>.</span>value(
</span></span><span style=display:flex><span>            measurement_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;athena_delete_monitoring_partition_sizes&#34;</span>,
</span></span><span style=display:flex><span>            value<span style=color:#f92672>=</span>row[<span style=color:#e6db74>&#34;sum_size&#34;</span>],
</span></span><span style=display:flex><span>            tags<span style=color:#f92672>=</span>{<span style=color:#f92672>**</span>tags, <span style=color:#f92672>**</span>{<span style=color:#e6db74>&#34;partition_date&#34;</span>: row[<span style=color:#e6db74>&#34;partition_field&#34;</span>]<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#34;=&#34;</span>)[<span style=color:#ae81ff>1</span>]}},
</span></span><span style=display:flex><span>        )
</span></span></code></pre></div><p>This task sends a metric with the size of each date partition, tagged with the name and id of the table.
We can create a dashboard in grafana that will monitor empty partitions.
Here is how the dashboard looks like:
<img src="https://drive.google.com/uc?id=11hKLY-2l0PIx8QrFjXoxWuLj9-6y78Oo" alt="Empty partitions panel"></p><p>This is how the panel is defined:
<img src="https://drive.google.com/uc?id=11nGJ3soe2VBunlnon8rtbaVDZv8EbA61" alt="Alert details">
We send an alert in case we found a single partition with a size that is lower than 1000 bytes
(we currently have a table with a partition that we know is smaller than 1000 bytes, so we alert of more than one partition with that size, but the core idea remains the same).</p><p>This concludes our datalake monitoring efforts. There is always a place to improve and we will surely fine tune the process as we continue
to improve our monitoring tools and capabilities, for example anomaly detection will be very useful here,
but for now i feel like this solution gives us a pretty high coverage for a low cost.</p><ul class=pa0></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"></aside></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://zigius.github.io/>&copy; zlog - the zigius blog 2023</a><div><div class=ananke-socials></div></div></div></footer></body></html>